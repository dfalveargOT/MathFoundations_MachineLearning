# Mathematical Foundations for Machine Learning

This course provides an in-depth exploration of the mathematical principles essential for understanding and applying machine learning algorithms. Key topics include the mathematical foundations of regression, classification, clustering, and dimensionality reduction in both supervised and unsupervised learning contexts. The course aims to bridge the gap between traditional mathematics courses and machine learning applications, offering students a cohesive learning experience with minimal prerequisites.

## Key Modules

The course is structured around fundamental questions in machine learning:

1. **What are the mathematical tools underlying machine learning algorithms?**
2. **How can these tools be applied to solve real-world data science problems?**
3. **What are the limitations and potential of these mathematical methods?**

## Learning Outcomes

- **Master core mathematical concepts** used in data science and machine learning.
- **Develop the ability to translate** machine learning problems into a mathematical framework.
- **Gain practical experience** in applying mathematical methods to real data.

## Course Project:

## Course Assignments:

- Clustering Iris Dataset and K-Means sum of sqaures minimization mathematical proof 
- 

## Course Content:

### 1. Linear Algebra Foundations
- Vectors, matrices, and matrix operations.
- Matrix decompositions, including LU, QR, EVD, and SVD.
- Matrix calculus.

### 2. Optimization Foundations
- Introduction to optimization techniques, including gradient descent and stochastic gradient descent (SGD).
- Proximal gradient methods and automatic differentiation.
- Optimality conditions.

![arm](assets/optimization.png)

### 3. Statistical Foundations
- Random variables, Gaussian distributions, and empirical risk minimization.
- Mixture models, maximal likelihood estimation.
- Decision theory and Gaussian discriminant analysis.

![arm](assets/kernel.png)

### 4. Regression and Classification
- Logistic regression, least squares, ridge, and Lasso regression.

![arm](assets/regression.png)

### 5. Neural Networks
- Multilayer perceptrons, activation functions, and deep networks.
- Backpropagation and training techniques.
- Convolutional networks and recurrent networks.
- Transformer architectures.

![arm](assets/NN.png)
![arm](assets/transformer.png)
![arm](assets/transformer2.png)

### 6. Dimensionality Reduction and Clustering
- Principal component analysis (PCA), matrix sketching, and randomized algorithms for SVD.
- Rank-k approximation, Eckart-Young bounds, and matrix completion problems.
- K-means clustering, Voronoi diagrams, and nearest neighbor classification.


### 8. Graph Representations and Spectral Clustering
- Graph Laplacian and Fiedler vectors.
- Spectral clustering with multiple eigenvectors.

![arm](assets/clustering.png)