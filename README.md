# Mathematical Foundations for Machine Learning

This course offers a comprehensive exploration of the mathematical principles critical for mastering and deploying machine learning algorithms. It covers the foundational mathematics underlying key machine learning techniques, including regression, classification, clustering, and dimensionality reduction, as well as advanced topics such as contrastive learning. The course is designed to bridge the gap between theoretical mathematics and practical machine learning, equipping students with both the deep mathematical understanding and the hands-on experience necessary to implement and apply machine learning models in diverse real-world scenarios.

## Key Modules

The course is structured around fundamental questions in machine learning:

1. **What are the mathematical tools underlying machine learning algorithms?**
2. **How can these tools be applied to solve real-world data science problems?**
3. **What are the limitations and potential of these mathematical methods?**

## Learning Outcomes

- **Master core mathematical concepts** used in data science and machine learning.
- **Develop the ability to translate** machine learning problems into a mathematical framework.
- **Gain practical experience** in applying mathematical methods to real data.

## Course Project:

## Course Assignments:

- Clustering Iris Dataset and K-Means sum of sqaures minimization mathematical proof 
- 

## Course Content:

### 1. Linear Algebra Foundations
- Vectors, matrices, and matrix operations.
- Matrix decompositions, including LU, QR, EVD, and SVD.
- Matrix calculus.

### 2. Optimization Foundations
- Introduction to optimization techniques, including gradient descent and stochastic gradient descent (SGD).
- Proximal gradient methods and automatic differentiation.
- Optimality conditions.

![arm](assets/optimization.png)

### 3. Statistical Foundations
- Random variables, Gaussian distributions, and empirical risk minimization.
- Mixture models, maximal likelihood estimation.
- Decision theory and Gaussian discriminant analysis.

![arm](assets/kernel.png)

### 4. Regression and Classification
- Logistic regression, least squares, ridge, and Lasso regression.

![arm](assets/regression.png)

### 5. Neural Networks
- Multilayer perceptrons, activation functions, and deep networks.
- Backpropagation and training techniques.
- Convolutional networks and recurrent networks.
- Transformer architectures.

![arm](assets/NN.png)
![arm](assets/transformer.png)
![arm](assets/transformer2.png)

### 6. Dimensionality Reduction and Clustering
- Principal component analysis (PCA), matrix sketching, and randomized algorithms for SVD.
- Rank-k approximation, Eckart-Young bounds, and matrix completion problems.
- K-means clustering, Voronoi diagrams, and nearest neighbor classification.


### 8. Graph Representations and Spectral Clustering
- Graph Laplacian and Fiedler vectors.
- Spectral clustering with multiple eigenvectors.

![arm](assets/clustering.png)